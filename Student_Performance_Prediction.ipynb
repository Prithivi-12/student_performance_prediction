{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.import and csv upload"
      ],
      "metadata": {
        "id": "PT6SAfEbRcnH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz94pnNGRfFZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data from GitHub\n",
        "url = 'https://raw.githubusercontent.com/Prithivi-12/student_performance_prediction/main/StudentsPerformance.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(\"‚úì Data loaded successfully!\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Data Preprocessing"
      ],
      "metadata": {
        "id": "pkF6t4cpSTkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic information\n",
        "print(\"=\"*60)\n",
        "print(\"DATASET INFORMATION\")\n",
        "print(\"=\"*60)\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STATISTICAL SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MISSING VALUES CHECK\")\n",
        "print(\"=\"*60)\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check for duplicates\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DUPLICATE CHECK\")\n",
        "print(\"=\"*60)\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"Duplicates found: {duplicates}\")\n",
        "if duplicates > 0:\n",
        "    df = df.drop_duplicates()\n",
        "    print(f\"‚úì Removed {duplicates} duplicate rows\")\n",
        "else:\n",
        "    print(\"‚úì No duplicates found\")\n",
        "\n",
        "# Store original data before encoding\n",
        "df_original = df.copy()\n",
        "print(\"\\n‚úì Saved original data as 'df_original'\")\n",
        "\n",
        "# Create encoded dataframe\n",
        "df_encoded = df.copy()\n",
        "print(\"‚úì Created 'df_encoded' for processing\")\n",
        "\n",
        "# Encode categorical variables\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ENCODING CATEGORICAL VARIABLES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "label_encoders = {}\n",
        "categorical_cols = ['gender', 'race/ethnicity', 'parental level of education',\n",
        "                    'lunch', 'test preparation course']\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df_encoded[col] = le.fit_transform(df_encoded[col])\n",
        "    label_encoders[col] = le\n",
        "    print(f\"‚úì Encoded '{col}'\")\n",
        "\n",
        "# Display comparison\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ORIGINAL DATA (Before Encoding)\")\n",
        "print(\"=\"*60)\n",
        "print(df_original.head())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ENCODED DATA (After Encoding)\")\n",
        "print(\"=\"*60)\n",
        "print(df_encoded.head())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ DATA PREPROCESSING COMPLETE\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "gqW4rdVySQqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "FmLNZmvLScTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df_encoded.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_heatmap.png')\n",
        "plt.show()\n",
        "print(\"‚úì Correlation heatmap saved as 'correlation_heatmap.png'\")\n",
        "\n",
        "# Score distributions\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "df_original['math score'].hist(bins=20, ax=axes[0], color='blue', alpha=0.7)\n",
        "axes[0].set_title('Math Score Distribution')\n",
        "axes[0].set_xlabel('Math Score')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "\n",
        "df_original['reading score'].hist(bins=20, ax=axes[1], color='green', alpha=0.7)\n",
        "axes[1].set_title('Reading Score Distribution')\n",
        "axes[1].set_xlabel('Reading Score')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "\n",
        "df_original['writing score'].hist(bins=20, ax=axes[2], color='red', alpha=0.7)\n",
        "axes[2].set_title('Writing Score Distribution')\n",
        "axes[2].set_xlabel('Writing Score')\n",
        "axes[2].set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('score_distributions.png')\n",
        "plt.show()\n",
        "print(\"‚úì Score distributions saved as 'score_distributions.png'\")\n",
        "\n",
        "# Boxplot for outlier detection\n",
        "plt.figure(figsize=(10, 6))\n",
        "df_original[['math score', 'reading score', 'writing score']].boxplot()\n",
        "plt.title('Boxplot for Score Outliers')\n",
        "plt.ylabel('Scores')\n",
        "plt.savefig('outlier_boxplot.png')\n",
        "plt.show()\n",
        "print(\"‚úì Boxplot saved as 'outlier_boxplot.png'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ EXPLORATORY DATA ANALYSIS COMPLETE\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "mrv_wYAUSdAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Feature Engineering & Selection"
      ],
      "metadata": {
        "id": "Ov1OJqQuTj_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create average score feature\n",
        "df_original['average_score'] = (df_original['math score'] +\n",
        "                                  df_original['reading score'] +\n",
        "                                  df_original['writing score']) / 3\n",
        "df_encoded['average_score'] = df_original['average_score']\n",
        "print(\"‚úì Created 'average_score' feature\")\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df_encoded[['gender', 'race/ethnicity', 'parental level of education',\n",
        "                'lunch', 'test preparation course', 'reading score', 'writing score']]\n",
        "y = df_encoded['math score']\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE SELECTION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Features (X): {X.shape}\")\n",
        "print(f\"Target (y): {y.shape}\")\n",
        "print(f\"\\nSelected Features: {list(X.columns)}\")\n",
        "print(f\"Target Variable: math score\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ FEATURE ENGINEERING & SELECTION COMPLETE\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "t3JCCBJXTjiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Model Building"
      ],
      "metadata": {
        "id": "jVGDt1cjTsT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DATA SPLITTING\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"\\n‚úì Feature scaling applied\")\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(alpha=1.0),\n",
        "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Train all models\n",
        "trained_models = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    trained_models[name] = model\n",
        "    print(f\"‚úì {name} trained successfully\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ MODEL BUILDING COMPLETE\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "9vrrqeyHTtY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Model Evaluation & Comparison"
      ],
      "metadata": {
        "id": "f27CSgY6Tzex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"MODEL EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in trained_models.items():\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    results[name] = {'RMSE': rmse, 'MAE': mae, 'R2 Score': r2}\n",
        "\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  RMSE: {rmse:.2f}\")\n",
        "    print(f\"  MAE: {mae:.2f}\")\n",
        "    print(f\"  R2 Score: {r2:.4f}\")\n",
        "\n",
        "# Create comparison dataframe\n",
        "results_df = pd.DataFrame(results).T\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL COMPARISON TABLE\")\n",
        "print(\"=\"*60)\n",
        "print(results_df)\n",
        "\n",
        "# Visualization of model comparison\n",
        "fig, ax = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "results_df['R2 Score'].plot(kind='bar', ax=ax[0], color='skyblue')\n",
        "ax[0].set_title('R2 Score Comparison')\n",
        "ax[0].set_ylabel('R2 Score')\n",
        "ax[0].set_xticklabels(results_df.index, rotation=45, ha='right')\n",
        "\n",
        "results_df['RMSE'].plot(kind='bar', ax=ax[1], color='salmon')\n",
        "ax[1].set_title('RMSE Comparison')\n",
        "ax[1].set_ylabel('RMSE')\n",
        "ax[1].set_xticklabels(results_df.index, rotation=45, ha='right')\n",
        "\n",
        "results_df['MAE'].plot(kind='bar', ax=ax[2], color='lightgreen')\n",
        "ax[2].set_title('MAE Comparison')\n",
        "ax[2].set_ylabel('MAE')\n",
        "ax[2].set_xticklabels(results_df.index, rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison.png')\n",
        "plt.show()\n",
        "print(\"\\n‚úì Model comparison chart saved as 'model_comparison.png'\")\n",
        "\n",
        "# Select best model\n",
        "best_model_name = results_df['R2 Score'].idxmax()\n",
        "best_model = trained_models[best_model_name]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BEST MODEL SELECTION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"üèÜ Best Model: {best_model_name}\")\n",
        "print(f\"   R2 Score: {results_df.loc[best_model_name, 'R2 Score']:.4f}\")\n",
        "print(f\"   RMSE: {results_df.loc[best_model_name, 'RMSE']:.2f}\")\n",
        "print(f\"   MAE: {results_df.loc[best_model_name, 'MAE']:.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ MODEL EVALUATION & COMPARISON COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n"
      ],
      "metadata": {
        "id": "Dlaty4nCT2wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Prediction Function"
      ],
      "metadata": {
        "id": "chqsSTJGUBWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_performance(gender, race, parent_edu, lunch, test_prep, reading, writing):\n",
        "    \"\"\"\n",
        "    Predict math score based on student characteristics and other scores.\n",
        "\n",
        "    Parameters:\n",
        "    - gender: 0 (Female) or 1 (Male)\n",
        "    - race: 0-4 (Group A-E)\n",
        "    - parent_edu: 0-5 (Some High School to Master's Degree)\n",
        "    - lunch: 0 (Standard) or 1 (Free/Reduced)\n",
        "    - test_prep: 0 (None) or 1 (Completed)\n",
        "    - reading: Reading score (0-100)\n",
        "    - writing: Writing score (0-100)\n",
        "\n",
        "    Returns:\n",
        "    - Predicted math score\n",
        "    \"\"\"\n",
        "    input_data = np.array([[gender, race, parent_edu, lunch, test_prep, reading, writing]])\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "    prediction = best_model.predict(input_scaled)\n",
        "    return prediction[0]\n",
        "\n",
        "# Example predictions\n",
        "print(\"=\"*60)\n",
        "print(\"PREDICTION EXAMPLES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Example 1\n",
        "sample1 = predict_performance(1, 2, 3, 0, 1, 75, 78)\n",
        "print(f\"\\nExample 1:\")\n",
        "print(f\"  Gender: Male, Race: Group C, Parent Edu: Associate's\")\n",
        "print(f\"  Lunch: Standard, Test Prep: Completed\")\n",
        "print(f\"  Reading: 75, Writing: 78\")\n",
        "print(f\"  Predicted Math Score: {sample1:.2f}\")\n",
        "\n",
        "# Example 2\n",
        "sample2 = predict_performance(0, 4, 5, 0, 1, 90, 88)\n",
        "print(f\"\\nExample 2:\")\n",
        "print(f\"  Gender: Female, Race: Group E, Parent Edu: Master's\")\n",
        "print(f\"  Lunch: Standard, Test Prep: Completed\")\n",
        "print(f\"  Reading: 90, Writing: 88\")\n",
        "print(f\"  Predicted Math Score: {sample2:.2f}\")\n",
        "\n",
        "# Example 3\n",
        "sample3 = predict_performance(1, 0, 1, 1, 0, 55, 52)\n",
        "print(f\"\\nExample 3:\")\n",
        "print(f\"  Gender: Male, Race: Group A, Parent Edu: High School\")\n",
        "print(f\"  Lunch: Free/Reduced, Test Prep: None\")\n",
        "print(f\"  Reading: 55, Writing: 52\")\n",
        "print(f\"  Predicted Math Score: {sample3:.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ PREDICTION FUNCTION READY\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "F5deAsMZUKBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.Save Models"
      ],
      "metadata": {
        "id": "2ctZavXS_pd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"SAVING MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save best model\n",
        "with open('best_model.pkl', 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "print(\"‚úì best_model.pkl saved\")\n",
        "\n",
        "# Save scaler\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "print(\"‚úì scaler.pkl saved\")\n",
        "\n",
        "# Save label encoders\n",
        "with open('label_encoders.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoders, f)\n",
        "print(\"‚úì label_encoders.pkl saved\")\n",
        "\n",
        "# Save model comparison results\n",
        "results_df.to_csv('model_comparison_results.csv')\n",
        "print(\"‚úì model_comparison_results.csv saved\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ ALL MODELS SAVED SUCCESSFULLY\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "1JVkNMjy_oZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.Deployment with Streamlit"
      ],
      "metadata": {
        "id": "z_-4dp6Q_s7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets -q\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "# Load models\n",
        "model = pickle.load(open('best_model.pkl', 'rb'))\n",
        "scaler = pickle.load(open('scaler.pkl', 'rb'))\n",
        "\n",
        "print(\"‚úì Models loaded successfully!\\n\")\n",
        "\n",
        "# Create interactive widgets\n",
        "display(HTML(\"\"\"\n",
        "<div style='background-color: #2ecc71; padding: 20px; border-radius: 10px; text-align: center;'>\n",
        "    <h1 style='color: white; margin: 0;'>üéì Student Performance Prediction System</h1>\n",
        "    <p style='color: white; margin: 5px 0 0 0;'>Predict math scores based on student factors</p>\n",
        "</div>\n",
        "<br>\n",
        "\"\"\"))\n",
        "\n",
        "gender = widgets.Dropdown(\n",
        "    options=['Female', 'Male'],\n",
        "    value='Male',\n",
        "    description='Gender:',\n",
        "    style={'description_width': '150px'},\n",
        "    layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "race = widgets.Dropdown(\n",
        "    options=['Group A', 'Group B', 'Group C', 'Group D', 'Group E'],\n",
        "    value='Group B',\n",
        "    description='Race/Ethnicity:',\n",
        "    style={'description_width': '150px'},\n",
        "    layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "parent_edu = widgets.Dropdown(\n",
        "    options=['Some High School', 'High School', 'Some College',\n",
        "             \"Associate's Degree\", \"Bachelor's Degree\", \"Master's Degree\"],\n",
        "    value=\"Bachelor's Degree\",\n",
        "    description='Parent Education:',\n",
        "    style={'description_width': '150px'},\n",
        "    layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "lunch = widgets.Dropdown(\n",
        "    options=['Standard', 'Free/Reduced'],\n",
        "    value='Standard',\n",
        "    description='Lunch Type:',\n",
        "    style={'description_width': '150px'},\n",
        "    layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "test_prep = widgets.Dropdown(\n",
        "    options=['None', 'Completed'],\n",
        "    value='None',\n",
        "    description='Test Prep:',\n",
        "    style={'description_width': '150px'},\n",
        "    layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "reading_score = widgets.IntSlider(\n",
        "    value=68,\n",
        "    min=0,\n",
        "    max=100,\n",
        "    step=1,\n",
        "    description='Reading Score:',\n",
        "    style={'description_width': '150px'},\n",
        "    layout=widgets.Layout(width='500px'),\n",
        "    continuous_update=False\n",
        ")\n",
        "\n",
        "writing_score = widgets.IntSlider(\n",
        "    value=81,\n",
        "    min=0,\n",
        "    max=100,\n",
        "    step=1,\n",
        "    description='Writing Score:',\n",
        "    style={'description_width': '150px'},\n",
        "    layout=widgets.Layout(width='500px'),\n",
        "    continuous_update=False\n",
        ")\n",
        "\n",
        "button = widgets.Button(\n",
        "    description='üéØ Predict Math Score',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='250px', height='50px')\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "def predict_score(b):\n",
        "    with output:\n",
        "        clear_output()\n",
        "\n",
        "        # Encode inputs\n",
        "        gender_enc = 1 if gender.value == 'Male' else 0\n",
        "        race_enc = ord(race.value[-1]) - ord('A')\n",
        "        parent_edu_mapping = {\n",
        "            'Some High School': 0,\n",
        "            'High School': 1,\n",
        "            'Some College': 2,\n",
        "            \"Associate's Degree\": 3,\n",
        "            \"Bachelor's Degree\": 4,\n",
        "            \"Master's Degree\": 5\n",
        "        }\n",
        "        parent_edu_enc = parent_edu_mapping.get(parent_edu.value, 2)\n",
        "        lunch_enc = 0 if lunch.value == 'Standard' else 1\n",
        "        test_prep_enc = 1 if test_prep.value == 'Completed' else 0\n",
        "\n",
        "        # Make prediction\n",
        "        input_data = np.array([[gender_enc, race_enc, parent_edu_enc, lunch_enc,\n",
        "                               test_prep_enc, reading_score.value, writing_score.value]])\n",
        "        input_scaled = scaler.transform(input_data)\n",
        "        prediction = model.predict(input_scaled)[0]\n",
        "\n",
        "        # Display results with styling\n",
        "        if prediction >= 80:\n",
        "            color = '#2ecc71'\n",
        "            emoji = 'üåü'\n",
        "            message = 'Excellent Performance!'\n",
        "        elif prediction >= 60:\n",
        "            color = '#3498db'\n",
        "            emoji = 'üëç'\n",
        "            message = 'Good Performance!'\n",
        "        else:\n",
        "            color = '#e74c3c'\n",
        "            emoji = 'üìö'\n",
        "            message = 'Needs Improvement'\n",
        "\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='background-color: {color}; padding: 30px; border-radius: 10px; text-align: center; margin-top: 20px;'>\n",
        "            <h2 style='color: white; margin: 0;'>üìä Prediction Result</h2>\n",
        "            <h1 style='color: white; font-size: 48px; margin: 10px 0;'>{prediction:.2f}/100</h1>\n",
        "            <h3 style='color: white; margin: 0;'>{emoji} {message}</h3>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "button.on_click(predict_score)\n",
        "\n",
        "# Display all widgets\n",
        "display(gender)\n",
        "display(race)\n",
        "display(parent_edu)\n",
        "display(lunch)\n",
        "display(test_prep)\n",
        "display(reading_score)\n",
        "display(writing_score)\n",
        "display(HTML(\"<br>\"))\n",
        "display(button)\n",
        "display(output)\n"
      ],
      "metadata": {
        "id": "DPKmzWTF_bH1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
